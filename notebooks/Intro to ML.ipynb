{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "Machine learning is concerned with the development of computer algorithms that improve their performance at given tasks with experience. Examples include:\n",
    "1. Speech recognition\n",
    "1. Image recognition\n",
    "1. Autonomous driving\n",
    "\n",
    "Take for example an algorithm that is designed to determine the class of a given hand written digit. This task is known as $\\textbf{classification}$ and involves assigning inputs to the algorithm to various classes. In this case, the digits are drawn from one of $\\{0, 1, \\ldots, 9\\}$. Examples from the famous [MNIST](http://yann.lecun.com/exdb/mnist/) data set are shown below\n",
    "\n",
    "![](../figures/MnistExamples.png)\n",
    "\n",
    "Given a single image as input, a machine learning algorithm would return the correct class. This can be expressed as a function mapping the set to images to the set $\\{0, 1, \\ldots, 9\\}$. \n",
    "\n",
    "How do we go about building such an algorithm? We need the following ingredients\n",
    "1. Data: Our algorithm will learn from experience which takes the form of labelled data examples. These could be images with a single digits\n",
    "2. We need a model that takes as input the image and returns the likely digit. This model will improve with access to more data\n",
    "3. We need a performance measure. How do we determine that the algorithm is improving with experience? This could involve measuring accuracy.\n",
    "4. A learning algorithm. Models often contain parameters whose values are modified to improve performance. The learning algorithm modifies these parameter values to improve performance.\n",
    "\n",
    "## Machine Learning in Action\n",
    "Let us explore machine learning using a concrete example in image recognition.\n",
    "\n",
    "### Image recognition\n",
    "We will see the steps involved in building an algorithm capable of recognising hand written digits. We start off with the data. We will us MNIST data which contains 70000 examples with labels. Lets obtain the data which are freely available. Often in applications, you have to obtain and label your own data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# data acquisition\n",
    "from keras.datasets import mnist\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data \n",
    "The data is divided into two sets, a training set and a test set. We use the training set to modify the parameters of our model and then use the test set to assess the performance.\n",
    "\n",
    "One of the first things to do with any data set is to visualise it. Let's visualise a random image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f7970752dd8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD7CAYAAABt9agKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXAgkXAgkXAgkXAgkXAgkXAgkXAj0H256JGejfQKkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f79797e1f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "index = random.choice(range(X_train.shape[0]))\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.imshow(X_train[index]);\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The digits are 28-by-28 pixels grayscale images which we represent as a matrix of numbers between 0 and 255 (8 bits per pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(X_train[index].min(), X_train[index].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition we flatten the matrix into a vector of length 784 and normalise the elements of the vector to the range $[0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also turn our labels into what is known as a one hot encoding. These are binary vectors where only one element is 1 and the rest are zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "from keras.utils import np_utils\n",
    "num_digits = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, num_digits)\n",
    "Y_test = np_utils.to_categorical(y_test, num_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[index])\n",
    "print(Y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "Next we create a model which will learn from the data. We will ignore the details for now but it is a multilayer perceptron whose output is the probability of the image belonging to each of the 10 digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models import create_mnist_model\n",
    "model = create_mnist_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is, the model parameters are random and we would not expect it to perform well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO4AAAD7CAYAAABt9agKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f797962ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_index = random.choice(range(X_test.shape[0]))\n",
    "plt.figure()\n",
    "plt.imshow(X_test[test_index].reshape(28, 28));\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(y_test[test_index])\n",
    "\n",
    "\n",
    "model.predict_classes(X_test[test_index, :][None, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "We now use the training data to improve the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.2823 - acc: 0.9321 - val_loss: 0.1874 - val_acc: 0.9658\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.2621 - acc: 0.9569 - val_loss: 0.2783 - val_acc: 0.9589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79c9de75f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "num_epoch = 2\n",
    "model.fit(X_train, \n",
    "          Y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=num_epoch, verbose=1, \n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "After training lets see how the model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.278253447118\n",
      "Test accuracy: 0.9589\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test[test_index, :][None, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the coming weeks and months, we will delve deeper into each of the steps listed and explore other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
